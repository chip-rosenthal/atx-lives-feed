#!/usr/bin/env ruby

require 'rubygems'
require 'logger'
require 'optparse'
require 'ostruct'
require 'open-uri'
require 'digest/md5'
require 'tmpdir'
require 'json'
require 'csv'

PROGNAME = File.basename($0)
USAGE = "usage: #{PROGNAME} [OPTIONS ...] (try \"--help\")"

TIMESTAMP = Time.now.to_i

# Location of source data.
URL_DATA_FEED = "https://data.austintexas.gov/api/views/ecmv-9xxi/rows.json"

# Version of the LIVES standard this implements, for "feed_info.csv".
# XXX - This is required by the standard, but the standard doesn't declare a version number. Srsly.
LIVES_VERSION = "unknown"

# Municipality name, for "feed_info.csv".
MUNI_NAME = "Austin, TX"
  
# URL of city website, for "feed_info.csv".
URL_MUNI_SITE = "http://www.austintexas.gov/"

# Email address of contact person, for "feed_info.csv".
EMAIL_CONTACT = "info@open-austin.org"

# Content for "legend.csv" file.
SCORE_LEGENDS = [
  # Name          Type    Required  Description
  # minimum_score number  Yes Minimum score that can be classified with this description
  # maximum_score number  Yes Maximum score that can be classified with this description
  # description   string  Yes Formatted version of the score in the format typically presented by the municipality. For example ‘A’ or ‘Pass’
  %w(minimum_score maximum_score description),
  [70, 100, "pass"],
  [0, 69, "re-inspection required"],
]  

# Content for README inserted into archive.
README_CONTENT = %Q[LIVES Data Feed for Austin, TX
      
This archive contains restaurant inspection data from Austin, TX.

It is formatted to the "Local Inspector Value-Entry Specification"
(LIVES) data standard.

  http://www.yelp.com/healthscores

This data feed is produced by Open Austin (www.open-austin.org)
based on data published by the City of Austin (data.austintexas.gov).

City of Austin publishes its restaurant scores at:

  https://data.austintexas.gov/dataset/Restaurant-Inspection-Scores/ecmv-9xxi

Problems with data values should be addressed to the City of Austin.

Problems with the file formats should be address to Open Austin. You
can reach us at #{EMAIL_CONTACT}.
]

@log = Logger.new($stderr)
@log.level = Logger::INFO

def die(*mssg)
  mssg[0].insert(0, PROGNAME + ": ") unless mssg[0] =~ /^usage:/
  STDERR.puts(mssg)
  exit(1)
end

@options = OpenStruct.new({
  :force => false,
  :source => URL_DATA_FEED,
  :destination => "lives.ci.austin.tx.us.zip",
  :path_zip => "zip",
})

begin
  OptionParser.new do |opts|

    opts.banner = USAGE
    opts.separator "\noptions:"

    opts.on("-v", "--[no-]verbose",
      "Show debugging log messages. Sets log level to DEBUG."
    ) {|flag| @log.level = (flag ? Logger::DEBUG : Logger::INFO)}

    opts.on("-q", "--[no-]quiet",
      "Suppress informational log messages. Sets log level to WARN."
    ) {|flag| @log.level = (flag ? Logger::WARN : Logger::INFO)}
      
    opts.on("-s", "--source PATH",
      "Specify data source, either a local file or URI. [default: #{@options.source}]"
    ) {|source| @options.source = source}
      
    opts.on("-d", "--destination PATH",
      "Specify output file. [default: #{@options.destination}]"
    ) {|destination| @options.destination = destination}
      
    opts.on("-f", "--[no-]force",
      "Force overwrite of existing destination file. [default: #{@options.force}]"
    ) {|flag| @options.force = flag}
      
    opts.on("--zip PATH",
      "Pathname to the \"zip\" program to use. [default: #{@options.path_zip}]"
    ) {|path| @options.path_zip = path}
      
    opts.on("-h", "-?", "--help",
      "Show help, including default values."
    ) {puts opts; exit}

  end.parse!
rescue OptionParser::ParseError => e
  die(e.message, USAGE)
end

die(USAGE) unless ARGV.empty?

if File.exist?(@options.destination) && !@options.force
  die("destination file already exists (specify \"--force\" to force overwrite)")
end

# Build artifacts in a temporary directory.
Dir.mktmpdir("lives") do |dir|  
  @log.info("created temporary directory: #{dir}")  
  
  # Track which businesses (restaurants) have been seen before.
  @did_business = {}
  
  @businesses = CSV.open("#{dir}/businesses.csv", "wb")
  @businesses << %w(business_id name address city state postal_code latitude longitude phone_number)
  
  @inspections = CSV.open("#{dir}/inspections.csv", "wb")
  @inspections << %w(business_id score date description type)
  
  @log.info("processing source: #{@options.source}")
  open(@options.source) do |fp|  
      
    raw = JSON.load(fp)
    
    # Produce list of column names, for elements in the "data" rows.
    cols = raw["meta"]["view"]["columns"].map {|a| a["name"]}
    
    # Iterate on each row in the dataset.
    raw["data"].each do |row|
      
      # Ruby magic. Produces a hash from list of col names and list of data values.
      h = Hash[[cols, row].transpose]
       
      # Example:
      # 
      # h = {
      #   "sid" => 12412,
      #   "id" => "0FF676CD-43A9-4898-B7FB-8C3CEF3D209F",
      #   "position" => 12412,
      #   "created_at" => 1358436716,
      #   "created_meta" => "433740",
      #   "updated_at" => 1358437071,
      #   "updated_meta" => "433740",
      #   "meta" => "{\n}",
      #   "Restaurant Name" => "Papa Murphy Take-N-Bake Pizza",
      #   "Zip Code" => "78750",
      #   "Inspection Date" => 1346137200,
      #   "Score" => "92",
      #   "Address" => [
      #     "{\"address\":\"12129 N FM 620 RD Bldg A\",\"city\":\"AUSTIN\",\"state\":\"TX\",\"zip\":\"78750\"}",
      #    "30.43180000017003",
      #    "-97.8007700000353",
      #    nil,
      #    false
      #  ]
      # }
      #
        
      #
      # Elements of the h["Address"] list are:
      #
      #   * human_address (a JSON-formatted string)
      #   * latitude
      #   * longitude
      #   * machine_address
      #   * needs_recoding
      #      
      address = JSON.parse(h["Address"][0])
      latitude = h["Address"][1]
      longitude = h["Address"][2]
      
      # City of Austin isn't publishing an id, so cobble up something.
      business_id = Digest::MD5.hexdigest("#{h["Restaurant Name"]}|#{address["address"]}")
        
      # If we haven't seen this business before, add it to the dataset.
      if ! @did_business.has_key?(business_id)
        @businesses << [
          # Name            Type    Required  Description   
               
          # business_id     string  Yes Unique identifier for the business. For many cities, this may be the license number.
          business_id,
          
          # name            string  Yes Common name of the business
          h["Restaurant Name"],        
         
          # address         string  Yes Street address of the business. For example: 706 Mission St.
          address["address"],        
         
          # city            string  No  City of the business. This field must be included if the file contains businesses from multiple cities.
          address["city"],        
         
          # state           string  No  State or province for the business. In the U.S. this should be the two-letter code for the state.
          address["state"],        
         
          # postal_code     string  No  Zip code or other postal code.
          address["zip"],        
         
          # latitude        number  No  Latitude of the business. This field must be a valid WGS 84 latitude. For example: 37.7859547
          latitude,        
          
          # longitude       number  No  Longitude of the business. This field must be a valid WGS 84 longitude. For example: -122.4024658
          longitude,        
    
          # phone_number    string  No  Phone number for a business including country specific dialing information. For example: +14159083801
          nil,
        ]

        @did_business[business_id] = true        
      end
      
      @inspections << [
        # Name            Type    Required  Description           
        
        # business_id     string  Yes   Unique identifier of the business for which this inspection was done
        business_id,
          
        # score           number  No*   Inspection score on a 0-100 scale. 100 is the highest score        
        h["Score"],
          
        # date            date    Yes   Date of the inspection in YYYYMMDD format
        Time.at(h["Inspection Date"]).strftime("%Y%m%d"),
          
        # description     string  No    Single line description containing details on the outcome of an inspection. Use of this field is only encouraged if no violations are provided.
        nil,
          
        # type            string  No    String representing the type of inspection. Must be (initial, routine, followup, complaint)
        nil,          
      ]
    
    end # each row    
  end # open

  @businesses.close
  @log.info("produced #{@businesses.lineno} business records")
  
  @inspections.close
  @log.info("produced #{@inspections.lineno} inspection records")      

  # Create "feed_info" file.
  CSV.open("#{dir}/feed_info.csv", "wb") do |csv|
    csv << %w(feed_date feed_version municipality_name municipality_url contact_email)
    csv << [
      # Name              Type    Required  Description   
                
      # feed_date         date    Yes  Date this feed was generated in YYYYMMDD format
      Time.now.strftime("%Y%m%d"),
      
      # feed_version      string  Yes  Version of the LIVES specification used to generate this feed. For example ‘0.4.1’
      LIVES_VERSION,
        
      # municipality_name string  Yes  Name of the municipality providing this feed. For example ‘San Francisco’ or ‘Multnomah County’
      MUNI_NAME,
        
      # municipality_url  string  No   URL of the publishing municipality’s website
      URL_MUNI_SITE,
     
      # contact_email     string  No   Email address of the person to contact regarding invalid data in this feed
      EMAIL_CONTACT,
        
      ]
  end

  # Create "legend" file.
  CSV.open("#{dir}/legend.csv", "wb") do |csv|
    SCORE_LEGENDS.each do |a|
      csv << a
    end
  end
  
  # Create a README for the archive.
  # This is not part of the LIVES standard, but seems helpful and hopefully won't break anything.
  open("#{dir}/README.txt", "w") do |readme|
    readme << README_CONTENT
  end  
  
  # Data processing complete. Archive it up.
  @log.info("invoking #{@options.path_zip} to generate archive")
  cmd = [
    @options.path_zip,
    (@log.level <= Logger::INFO ? '--verbose' : '--quiet'),
    "--recurse-paths",
    "--junk-paths",
    "#{@options.destination}.#{TIMESTAMP}",
    dir
  ];
  @log.debug("executing: #{cmd.join(' ')}")
  system(*cmd)
  
end # Dir.mktmpdir

File.unlink(@options.destination) if File.exist?(@options.destination)
File.rename("#{@options.destination}.#{TIMESTAMP}", @options.destination)

@log.info("archive complete: #{@options.destination}")
